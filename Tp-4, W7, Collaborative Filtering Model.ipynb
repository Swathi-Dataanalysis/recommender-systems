{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Model #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is a method used in recommender systems to predict a user's interests based on the preferences of a larger user group. It operates under the principle that users who agreed in the past will agree in the future about certain items. The two main types are:\n",
    "\n",
    "User-Based Collaborative Filtering: This method makes recommendations based on the similarities between users. It's effective when there are fewer users than items, but it can face challenges in scalability and changing user preferences.\n",
    "\n",
    "Item-Based Collaborative Filtering: This approach focuses on the similarities between items, based on user ratings or interactions. It's preferred in cases where the number of items is smaller than the number of users and is generally more stable as items tend to change less frequently than user preferences.\n",
    "\n",
    "When to Use:\n",
    "User-based filtering is suitable for systems with stable user preferences and a manageable user base.\n",
    "\n",
    "Item-based filtering works well in larger systems with more users, as it tends to be more scalable and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Formulating a Prediction Question:\n",
    "Our primary objective is to leverage a collaborative filtering recommender algorithm to predict movie ratings by users.\n",
    "\"Based on the MovieLens dataset, how can we predict the rating a user would give to a movie they haven't seen yet, based on the ratings provided by users with similar viewing habits?\" \n",
    "\n",
    "    This involves identifying user similarities based on their movie rating patterns and utilizing these similarities to predict ratings for unseen movies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dataset\n",
    "For this assignment I chose a MovieLens Dataset from kaggle repository it contain files movies.csv and ratings.csv. These datasets are commonly used in building movie recommender systems, where movies.csv typically contains information about the movies, such as movie IDs, titles, and genres, and ratings.csv includes user ratings for these movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Importing Libraries:\n",
    "To build a recommender system in Python, we need to import libraries such as pandas for data manipulation, numpy for numerical operations, and surprise for building and evaluating recommender systems.\n",
    "\n",
    "4. Loading and Preprocessing the Dataset:\n",
    "We'll load the datasets into data frames and preprocess them. This include handling missing values, encoding categorical variables, and merging datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   movieId                               title  \\\n",
       " 0        1                    Toy Story (1995)   \n",
       " 1        2                      Jumanji (1995)   \n",
       " 2        3             Grumpier Old Men (1995)   \n",
       " 3        4            Waiting to Exhale (1995)   \n",
       " 4        5  Father of the Bride Part II (1995)   \n",
       " \n",
       "                                         genres  \n",
       " 0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       " 1                   Adventure|Children|Fantasy  \n",
       " 2                               Comedy|Romance  \n",
       " 3                         Comedy|Drama|Romance  \n",
       " 4                                       Comedy  ,\n",
       "    userId  movieId  rating  timestamp\n",
       " 0       1        1     4.0  964982703\n",
       " 1       1        3     4.0  964981247\n",
       " 2       1        6     4.0  964982224\n",
       " 3       1       47     5.0  964983815\n",
       " 4       1       50     5.0  964982931)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the datasets\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Display the first few rows of each dataset for exploration\n",
    "movies_head = movies.head()\n",
    "ratings_head = ratings.head()\n",
    "\n",
    "movies_head, ratings_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets on 'movieId'\n",
    "df = pd.merge(ratings, movies, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1106635946</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp             title  \\\n",
       "0       1        1     4.0   964982703  Toy Story (1995)   \n",
       "1       5        1     4.0   847434962  Toy Story (1995)   \n",
       "2       7        1     4.5  1106635946  Toy Story (1995)   \n",
       "3      15        1     2.5  1510577970  Toy Story (1995)   \n",
       "4      17        1     4.5  1305696483  Toy Story (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame for a quick overview\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "title        0\n",
      "genres       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      " 4   title      100836 non-null  object \n",
      " 5   genres     100836 non-null  object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Display the information of the DataFrame for a quick overview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate summary statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Splitting the Dataset\n",
    "Before building the recommender system model, we need to split the data into training and testing sets. This is crucial for training the model and then evaluating its performance on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Defining a reader with the rating scale\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "# Loading the dataset into Surprise's format\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Splitting the dataset into training and testing sets (75% train, 25% test)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Building the Recommender System\n",
    "For collaborative filtering choosing Singular Value Decomposition (SVD) algorithm is a popular choice for this purpose and training it on train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x12072bb50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "model = SVD()\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Making Predictions and Measuring Accuracy:\n",
    " Making predictions on the test set and evaluating the performance using metrics RMSE (Root Mean Square Error) and MAE (Mean Absolute Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8736\n",
      "MAE:  0.6712\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Compute and print RMSE and MAE\n",
    "accuracy_rmse = accuracy.rmse(predictions)\n",
    "accuracy_mae = accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE (Root Mean Square Error) - 0.8755:\n",
    "An RMSE of 0.8755 means that the standard deviation of the prediction errors (i.e., the differences between actual and predicted values) is approximately 0.8755 ratings points.\n",
    "Lower RMSE values are better as they indicate smaller errors. Considering typical movie rating scales (like 1-5 or 0-10), an RMSE of 0.8755 suggests a moderate level of prediction error.\n",
    "MAE (Mean Absolute Error) - 0.6732:\n",
    "A MAE of 0.6732 means that, on average, the absolute error of the predictions is 0.6732 ratings points.\n",
    "Like RMSE, lower values of MAE are better. A MAE of 0.6732 is relatively low, indicating that the model has decent accuracy in predictions.\n",
    "\n",
    "Interpreting These Results in Context:\n",
    "Goodness of Fit: Both RMSE and MAE are relatively low, which indicates that the model has a good fit to the data and can make reasonably accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Fine-tuning with GridSearchCV\n",
    "Using GridSearchCV to find the optimal parameters for the SVD algorithm. This step helps in enhancing the model's performance by tuning its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8865458940632052, {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.4})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Define a parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_epochs': [5, 10, 20], \n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.4, 0.6]\n",
    "}\n",
    "\n",
    "# Use grid search to find the best parameters\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "best_rmse = gs.best_score['rmse']\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "best_params = gs.best_params['rmse']\n",
    "\n",
    "best_rmse, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best RMSE Score - 0.8860:\n",
    "This is the lowest (best) RMSE (Root Mean Square Error) achieved by the GridSearchCV process.\n",
    "An RMSE of 0.8860 means that the standard deviation of the prediction errors in your model is about 0.8860 rating points.\n",
    "In the context of movie ratings (often on a scale from 1 to 5 or 0 to 10), this RMSE indicates a moderate level of accuracy. It implies that the average error in predicting a movie rating is less than one rating point.\n",
    "\n",
    "Best Parameters:\n",
    "n_epochs: 20 - This indicates that the best results were obtained when the model was iterated 20 times over the training set. In the context of algorithms like SVD, an epoch is a single pass through the entire training set. More epochs can lead to a better-trained model but also increase the risk of overfitting.\n",
    "lr_all: 0.005 - This is the learning rate for all parameters, which controls the size of the steps the algorithm takes during optimization. A learning rate of 0.005 suggests a balance between speed and accuracy of convergence.\n",
    "reg_all: 0.4 - This refers to the regularization term, which is used to prevent overfitting by penalizing larger model parameters. A value of 0.4 indicates a moderate level of regularization, balancing model complexity and generalization to new data.\n",
    "\n",
    "Interpretation and Context:\n",
    "Model Optimization: The combination of parameters leading to this RMSE value is an optimal setting for the model according to GridSearchCV. It represents a balance between overfitting and underfitting, learning speed, and regularization.\n",
    "\n",
    "Performance Consideration: While the RMSE of 0.8860 is relatively good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Recommender System using KNNBasic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9736\n",
      "MAE:  0.7505\n"
     ]
    }
   ],
   "source": [
    "from surprise.accuracy import rmse, mae\n",
    "\n",
    "# Configure the algorithm to use user-based collaborative filtering\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True  # for user-based collaborative filtering; set to False for item-based\n",
    "}\n",
    "\n",
    "# Create the KNNBasic model\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Calculate and print RMSE and MAE\n",
    "accuracy_rmse = rmse(predictions)\n",
    "accuracy_mae = mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity Matrix Computation:\n",
    "\"Computing the cosine similarity matrix... Done computing similarity matrix.\" This message indicates that the KNN algorithm has computed the similarity matrix using the cosine similarity metric.\n",
    "Cosine similarity is a measure that calculates the cosine of the angle between two vectors. In the context of a recommender system, these vectors represent user preferences or item features. A cosine similarity close to 1 implies a high degree of similarity.\n",
    "\n",
    "RMSE (Root Mean Square Error) - 0.9802:\n",
    "RMSE is used to measure the average magnitude of the errors between predicted and actual ratings. An RMSE of 0.9802 suggests that the standard deviation for the prediction errors is around 0.9802 points on the rating scale.\n",
    "Compared to other models, this RMSE might be considered slightly high, depending on the rating scale used (typically 1-5 or 0-10). A lower RMSE is generally desired as it indicates higher prediction accuracy.\n",
    "\n",
    "MAE (Mean Absolute Error) - 0.7542:\n",
    "MAE measures the average absolute difference between predicted and actual ratings. A MAE of 0.7542 means that, on average, the model's predictions are about 0.7542 points off from the actual ratings.\n",
    "Like RMSE, a lower MAE is preferable as it indicates more accurate predictions.\n",
    "\n",
    "Interpretation and Context:\n",
    "Model Performance: The RMSE and MAE values suggest that your KNN model with cosine similarity provides moderately accurate predictions. However, the performance might not be as high as desired, especially if compared to other models or algorithms.\n",
    "\n",
    "Suitability of the Model: The effectiveness of a KNN-based model can depend heavily on the nature of the data. Sparse datasets or datasets with a wide range of preferences can sometimes challenge KNN's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9538340612469226\n",
      "{'k': 20, 'sim_options': {'name': 'msd', 'user_based': True}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30],\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine', 'pearson'],\n",
    "        'user_based': [True]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use grid search to find the best parameters for KNNBasic\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# Best score and parameters\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the results of the KNN model with  SVD model: ##\n",
    "RMSE Comparison:\n",
    "The SVD model has a lower RMSE (0.8755) compared to the KNN model (0.9802).\n",
    "A lower RMSE indicates that the SVD model's predictions are, on average, closer to the actual ratings than those of the KNN model.\n",
    "The SVD model seems to better capture the variance in the user-item ratings matrix.\n",
    "MAE Comparison:\n",
    "Similarly, the SVD model shows a lower MAE (0.6732) than the KNN model (0.7542).\n",
    "This suggests that the SVD model's predictions are more accurate on average, with less absolute error in its predictions.\n",
    "Interpretation:\n",
    "Model Effectiveness: The SVD model appears to be more effective for this particular dataset based on both RMSE and MAE metrics. This suggests that it might be better at capturing user preferences and predicting ratings in the dataset.\n",
    "\n",
    "Algorithm Differences: These differences can be attributed to the underlying mechanisms of the algorithms. SVD is a matrix factorization technique that can capture complex patterns in the data, often performing well even with sparse datasets. KNN, on the other hand, relies on similarity between users or items, which might not be as effective if the dataset doesn’t exhibit strong similarity patterns or is sparse.\n",
    "Context and Data Characteristics: The choice between SVD and KNN should also consider the specific characteristics of the dataset and the application's needs. For example, if interpretability is key, KNN might be preferred despite its slightly lower performance.\n",
    "\n",
    "Conclusion:\n",
    "Based on the comparison, the SVD model seems to be a better fit for the dataset in terms of both RMSE and MAE. However, the final decision should also take into account factors like computational efficiency, scalability, and the specific nature of the dataset and recommendation context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based collaborative filtering: ##\n",
    "In item-based collaborative filtering, the system makes recommendations based on the similarity between items rather than users. This approach is particularly useful when we have more users than items, as it's often easier to calculate the similarity between a smaller set of items than a larger set of users.\n",
    "\n",
    "Here's a general outline of how to implement item-based collaborative filtering, especially using the surprise library in Python:\n",
    "\n",
    "1. Choose the Right Algorithm\n",
    "For item-based collaborative filtering, we can use algorithms like KNNBasic, but with a configuration that focuses on item similarities. In surprise, this can be done by setting the user_based field to False in the sim_options argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False  # compute similarities between items\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1744ad7d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "algo.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9731\n",
      "MAE:  0.7582\n"
     ]
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "# Calculate and print RMSE and MAE\n",
    "accuracy_rmse = rmse(predictions)\n",
    "accuracy_mae = mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9142679036935704\n",
      "{'k': 40, 'sim_options': {'name': 'msd', 'min_support': 1, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'k': [20, 30, 40],\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine'],\n",
    "        'min_support': [1, 5],\n",
    "        'user_based': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use grid search to find the best parameters for KNNBasic\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# Best score and parameters\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best RMSE Score - 0.9143:\n",
    "The best RMSE (Root Mean Square Error) achieved across all parameter combinations was 0.9143.\n",
    "RMSE is a standard measure of the average magnitude of the prediction error, implying that the average error in your model’s predictions is about 0.9143 points on the rating scale.\n",
    "\n",
    "Best Parameters:\n",
    "k: 40 - The optimal number of neighbors was found to be 40. This means the best results were achieved when each prediction considered the 40 most similar users or items.\n",
    "\n",
    "sim_options: A dictionary indicating the best combination of similarity options:\n",
    "name: 'msd' - The best similarity metric was the Mean Squared Difference. This metric performs calculations based on the squared difference between ratings.\n",
    "\n",
    "min_support: 1 - The minimum number of common items needed for the similarity calculation was 1.\n",
    "user_based: False - This indicates that the best results were achieved using item-based collaborative filtering rather than user-based.\n",
    "\n",
    "Interpretation:\n",
    "Model Performance: An RMSE of 0.9143 suggests moderate accuracy. Whether this is acceptable depends on the context of the application and the nature of the dataset.\n",
    "Item-Based Filtering Effectiveness: The fact that user_based was set to False with the best performance suggests that for this particular dataset, item-based collaborative filtering is more effective than user-based.\n",
    "Parameter Suitability: The combination of k=40 and msd for similarity indicates that considering a larger number of neighbors and using the MSD metric for calculating similarities between items leads to more accurate predictions.\n",
    "\n",
    "Conclusion:\n",
    "This grid search has helped  identify the most effective parameters for the collaborative filtering model, specifically pointing towards an item-based approach with a fairly high number of neighbors. The RMSE indicates that there is room for improvement, and depending on the requirements of the application, further tuning or a different approach might be needed for better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "Harper, F. M., & Konstan, J. A. (2015). The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS), 5(4), Article 19. http://dx.doi.org/10.1145/2827872\n",
    "\n",
    "Kaggle. (2018). MovieLens [Data set]. https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
